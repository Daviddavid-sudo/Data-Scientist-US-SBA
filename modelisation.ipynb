{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, make_scorer, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset avec suppression de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_cleaned_0.9886.csv\")\n",
    "X = df.drop(columns=['MIS_Status']) \n",
    "y = df['MIS_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8981   809]\n",
      " [  591 26128]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96165329096935"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, booster='gbtree', max_depth=13, alpha=8,learning_rate=0.35,n_estimators=150)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "xgb_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "roc_auc1 = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "best_params = {}\n",
    "# temp_list = np.linspace(0,1,21)\n",
    "list = range(0,1)\n",
    "for x in list :\n",
    "    params = {\n",
    "            'max_depth': 11,\n",
    "            'alpha': 6,\n",
    "            'learning_rate': 0.35,\n",
    "            'lambda': 8,\n",
    "            'n_estimators': 150\n",
    "        }\n",
    "\n",
    "    xgb_clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "    y_prob = xgb_clf.predict_proba(X_test)[:, 1] \n",
    "    roc_auc11 = roc_auc_score(y_test, y_prob)\n",
    "    f1_macro = f1_score(y_test, xgb_clf.predict(X_test), average='macro')\n",
    "    \n",
    "\n",
    "    # score = xgb_clf.score(X_test,y_test)\n",
    "    if max_score<roc_auc11:\n",
    "        best_params = params\n",
    "        max_score = roc_auc11\n",
    "print(best_params)\n",
    "print(max_score)\n",
    "print(f'F1-macro: {f1_macro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc11:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs (FPR)')\n",
    "plt.ylabel('Taux de vrais positifs (TPR)')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset sans suppression de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_cleaned_0.9832.csv\")\n",
    "X = df.drop(columns=['MIS_Status']) \n",
    "y = df['MIS_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Calcul de l'AUC\n",
    "roc_auc1 = auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, booster='gbtree', max_depth=13, alpha=8,learning_rate=0.35,n_estimators=150)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "xgb_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc1:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs (FPR)')\n",
    "plt.ylabel('Taux de vrais positifs (TPR)')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "best_params = {}\n",
    "# temp_list = np.linspace(0,1,21)\n",
    "list = range(0,1)\n",
    "for x in list :\n",
    "    params = {\n",
    "            'max_depth': 11,\n",
    "            'alpha': 6,\n",
    "            'learning_rate': 0.35,\n",
    "            'lambda': 8,\n",
    "            'n_estimators': 150\n",
    "        }\n",
    "\n",
    "    xgb_clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "    y_prob = xgb_clf.predict_proba(X_test)[:, 1]  # Probabilités pour la classe positive\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    f1_macro = f1_score(y_test, xgb_clf.predict(X_test), average='macro')\n",
    "    \n",
    "\n",
    "    # score = xgb_clf.score(X_test,y_test)\n",
    "    if max_score<roc_auc:\n",
    "        best_params = params\n",
    "        max_score = roc_auc\n",
    "print(best_params)\n",
    "print(max_score)\n",
    "print(f'F1-macro: {f1_macro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs (FPR)')\n",
    "plt.ylabel('Taux de vrais positifs (TPR)')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.bar(range(len(xgb_model.feature_importances_)), xgb_model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_clf.feature_importances_\n",
    "for feature, importance in zip(X_train.columns, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "importances = xgb_clf.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "\n",
    "feat_imp_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "feat_imp_df = feat_imp_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df, palette='viridis')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sami/Documents/Dev_IA/Data-Scientist-US-SBA/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xid=4549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0].values, X_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[1].values, X_test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[2].values, X_test.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model = LogisticRegression(solver='saga')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilités pour la classe positive\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f'AUC-ROC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'F1_macro': make_scorer(f1_score, average='macro'),\n",
    "           'AUC': make_scorer(roc_auc_score)}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
